# Prompt
What are the things that you would need to do to accomplish this task?

```
Create a Python module that integrates with the OpenAI API to generate dynamic narrative content. The module should take a narrative prompt template and dynamic variables (e.g., location type, tone, required elements) to generate text. Include error handling and caching using Redis.
```

# Context

- **Purpose:**  
    Enhance static narrative with dynamic, context-sensitive content.
    
- **Key Functions:**
    
    - **API Integration:** Connect with OpenAI, Anthropic, or similar APIs.
        
    - **Prompt Management:** Insert dynamic variables into narrative templates.
        
    - **Content Validation:** Ensure AI-generated content fits the game’s tone and constraints.
        
    - **Fallbacks:** Predefined content for critical story nodes.
        
- **Considerations:**
    
    - Use caching (with Redis) for AI responses to optimize performance.
        
    - Maintain a narrative memory log to ensure coherence over longer play sessions.

# Reply
Hey Ian, it's skippy. Here’s a detailed breakdown of the tasks you’d need to complete to build this Python module:

---

### 1. Set Up the Module Structure

- **Module File:**  
    Create a new file (e.g., `narrative_engine/ai_generator.py`) within your narrative_engine module.
    
- **Configuration Handling:**  
    Allow the module to accept API keys and Redis connection parameters from the main Flask app or environment variables, rather than hardcoding values.


#### a. Create the Module File

- **Folder Structure:**  
    Ensure you have a directory for your module. For example, if you haven’t already, create a folder named `narrative_engine` and inside it, add an `__init__.py` file (which can be empty). This tells Python that the folder is a package.
    
- **New File:**  
    Create a new file called `ai_generator.py` inside the `narrative_engine` folder. Your folder might look like this:
    
    ```
    narrative_engine/
        __init__.py
        ai_generator.py
    ```
    

#### b. Configuration Handling

- **Goal:**  
    Your module should not hardcode sensitive or environment-specific information (like API keys or connection parameters). Instead, it should accept these values from the main Flask app’s configuration or environment variables.
    
- **How to Do It:**
    
    1. **Use a Function for Initialization:**  
        In your `ai_generator.py`, define an `init_app` function that takes a Flask app object as a parameter. This function reads configuration values from the app’s config.
        
    2. **Environment Variables as Fallback:**  
        Use Python’s `os.environ.get` to pull values from environment variables if they're not explicitly set in your Flask app configuration.
        
    3. **Store the Config Values:**  
        For instance, store the OpenAI API key and Redis URL in module-level variables or in a configuration object that is accessible throughout the module.
        

#### c. Sample Code for Configuration Handling

Here's a code snippet to illustrate the concepts:

```python
# narrative_engine/ai_generator.py

import os
import redis
import openai

# Module-level variables to hold configuration settings
OPENAI_API_KEY = None
REDIS_URL = None
redis_client = None

def init_app(app):
    """
    Initialize the AI generator module with settings from a Flask app.
    Expected configuration keys:
      - OPENAI_API_KEY
      - REDIS_URL
    """
    global OPENAI_API_KEY, REDIS_URL, redis_client
    
    # Read the API key and Redis URL from the app's config, with environment variable fallback
    OPENAI_API_KEY = app.config.get('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY'))
    REDIS_URL = app.config.get('REDIS_URL', os.environ.get('REDIS_URL'))
    
    # Validate the configurations, and you can log or raise errors if necessary
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API key is not set. Please define it in your config or set the OPENAI_API_KEY environment variable.")
    if not REDIS_URL:
        raise ValueError("Redis URL is not set. Please define it in your config or set the REDIS_URL environment variable.")
    
    # Setup OpenAI with the API key
    openai.api_key = OPENAI_API_KEY
    
    # Connect to Redis
    redis_client = redis.Redis.from_url(REDIS_URL)
    
    # Optionally, log the successful initialization
    app.logger.info("AI Generator module initialized with OpenAI API and Redis.")

# Additional functions for the module would go below,
# for example, functions to generate narrative content dynamically.
```

---

### Recap

- **Module File:**  
    Create `narrative_engine/ai_generator.py` and ensure `narrative_engine/__init__.py` exists.
    
- **Configuration Handling:**  
    Implement an `init_app` function that:
    
    - Reads configuration values (like `OPENAI_API_KEY` and `REDIS_URL`) from the Flask app config or environment.
        
    - Sets up module-level variables.
        
    - Initializes the OpenAI API (by setting the key) and the Redis client.
        

With this setup, you maintain a clean separation between your module logic and the application-specific configuration, which makes your module more reusable and easier to manage. Let me know if you need more details or further guidance on this, Ian!

---

### 2. API Integration with OpenAI

- **Import OpenAI Library:**  
    Use the official OpenAI Python SDK (or a similar package for other APIs like Anthropic).
    
- **API Call Function:**  
    Write a function that constructs and sends a request to the API using your narrative prompt.
    
- **Dynamic Variables:**  
    Build functionality to insert dynamic variables such as location type, tone, and required elements into a narrative prompt template (e.g., using Python’s string formatting or a templating engine).
    

- **Install and Import:**  
    First, ensure you’ve installed the OpenAI Python package. You can install it using pip:
    
    ```bash
    pip install openai
    ```
    
    Then, import it at the top of your module file (e.g., `narrative_engine/ai_generator.py`):
    
    ```python
    import openai
    ```
    
- **Why It’s Important:**  
    This provides you with the functions and classes necessary to interact with the OpenAI API. Later on, you'll use methods like `openai.Completion.create()` or `openai.ChatCompletion.create()` to generate your narrative content.
    

---

### 2. API Call Function

- **Goal:**  
    Create a function that builds a prompt, sends it to the OpenAI API, and returns the AI-generated text.
    
- **Steps to Implement:**
    
    1. **Build Your Request:**  
        Format the narrative prompt with the dynamic data (more on that in the next section).
        
    2. **Send the Request:**  
        Use OpenAI’s API call (e.g., using `openai.Completion.create()` for a completion or `openai.ChatCompletion.create()` if you’re using a Chat-based model).
        
    3. **Handle Errors:**  
        Wrap the API call in a try/except block to catch issues like network errors or API exceptions.
        
- **Sample API Call Function:**
    
    ```python
    def generate_narrative(prompt):
        """
        Generates narrative content using the OpenAI API based on the provided prompt.
    
        :param prompt: The string prompt, formatted with dynamic variables.
        :return: The generated narrative text.
        """
        try:
            response = openai.Completion.create(
                engine="davinci",  # or your engine of choice, e.g., "gpt-3.5-turbo" for ChatCompletion
                prompt=prompt,
                max_tokens=150,
                temperature=0.8  # controls randomness, adjust as needed
            )
            # Extract the first choice's text from the response
            narrative_text = response['choices'][0]['text'].strip()
            return narrative_text
        except Exception as error:
            # Log error (in a real app, integrate with your logging system)
            print(f"Error during API call: {error}")
            # Fallback content in case of error
            return "The narrative could not be generated at this time."
    ```
    

---

### 3. Dynamic Variables in Narrative Templates

- **Goal:**  
    Insert dynamic variables (like location type, tone, required elements) into your narrative prompt template before sending it to the API.
    
- **Steps to Implement:**
    
    1. **Define a Template:**  
        Create a base narrative prompt with placeholders for your dynamic variables. For instance:
        
        ```python
        narrative_template = (
            "Generate a detailed description of a {location_type} environment, "
            "using a {tone} tone. Be sure to include the following elements: {required_elements}."
        )
        ```
        
    2. **Substitute Dynamic Variables:**  
        Use Python’s built-in string formatting to replace these placeholders with actual values. You can use the `.format(**kwargs)` method for this:
        
        ```python
        def build_prompt(template, **kwargs):
            """
            Inserts dynamic variables into the provided template.
        
            :param template: A narrative prompt template with placeholders.
            :param kwargs: A dictionary of dynamic values to insert into the template.
            :return: A fully formatted prompt ready for the API.
            """
            return template.format(**kwargs)
        ```
        
    3. **Integrate With API Call:**  
        Combine the dynamic prompt building with your API call function.
        
- **Combined Example:**
    
    ```python
    # Define the narrative prompt template
    NARRATIVE_TEMPLATE = (
        "Generate a detailed description of a {location_type} environment, "
        "using a {tone} tone. Be sure to include the following elements: {required_elements}."
    )
    
    def build_prompt(template, **kwargs):
        """
        Inserts dynamic variables into the provided template.
        
        :param template: A narrative prompt template with placeholders.
        :param kwargs: A dictionary of dynamic values to insert into the template.
        :return: A fully formatted prompt.
        """
        return template.format(**kwargs)
    
    def generate_dynamic_narrative(location_type, tone, required_elements):
        """
        Combines prompt building and API call to generate narrative content dynamically.
        
        :param location_type: Type of the location (e.g., 'dungeon', 'forest').
        :param tone: The desired tone of the narrative (e.g., 'mysterious', 'whimsical').
        :param required_elements: Key elements that must be included in the narrative.
        :return: AI-generated narrative text.
        """
        # Build the prompt with dynamic variables
        prompt = build_prompt(
            NARRATIVE_TEMPLATE,
            location_type=location_type,
            tone=tone,
            required_elements=required_elements
        )
        
        # Get narrative content from the API
        narrative = generate_narrative(prompt)
        return narrative
    ```
    

---

### Recap

- **Importing the Library:**  
    Install and import the OpenAI package using `import openai`.
    
- **API Call Function:**  
    Write a robust function to send requests to the OpenAI API that includes error handling. Use methods like `openai.Completion.create()`.
    
- **Dynamic Variables:**  
    Create a narrative prompt template with placeholders and use Python’s string formatting (or a templating engine, if you prefer) to inject dynamic variables such as location type, tone, and required elements.
    

By following these steps, you'll have a module that dynamically generates narrative content based on context, handling both API interactions and dynamic prompt generation. Let me know if you need more guidance, Ian!

---

### 3. Prompt Management and Content Validation

- **Prompt Template Management:**  
    Develop methods to:
    
    - Accept a narrative prompt template.
        
    - Replace placeholders with dynamic data from the game state.
        
- **Content Validation:**  
    Implement checks to ensure the AI-generated text fits the desired tone and constraints. This might include:
    
    - Simple validation rules (string checks for required elements).
        
    - Fallback strategies if content does not meet criteria.
        
- **Fallback Handling:**  
    Define predefined, safe narrative snippets that can be used when the API fails or returns unsatisfactory output.
    

Hey Ian, it's skippy. Below is an updated version of your `ai_generator.py` file that includes content validation and fallback handling. This version uses simple string-based validation to ensure that the generated narrative includes all required elements and falls back to a predefined narrative snippet if it doesn't.

```python
# narrative_engine/ai_generator.py

import os
import redis
import openai

# Module-level variables to hold configuration settings
OPENAI_API_KEY = None
REDIS_URL = None
redis_client = None

def init_app(app):
    """
    Initialize the AI generator module with settings from a Flask app.
    Expected configuration keys:
      - OPENAI_API_KEY
      - REDIS_URL
    """
    global OPENAI_API_KEY, REDIS_URL, redis_client
    
    OPENAI_API_KEY = app.config.get('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY'))
    REDIS_URL = app.config.get('REDIS_URL', os.environ.get('REDIS_URL'))
    
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API key is not set. Please define it in your config or set the OPENAI_API_KEY environment variable.")
    if not REDIS_URL:
        raise ValueError("Redis URL is not set. Please define it in your config or set the REDIS_URL environment variable.")
    
    openai.api_key = OPENAI_API_KEY
    redis_client = redis.Redis.from_url(REDIS_URL)
    
    app.logger.info("AI Generator module initialized with OpenAI API and Redis.")

def generate_narrative(prompt):
    """
    Generates narrative content using the OpenAI API based on the provided prompt.
    
    :param prompt: The string prompt, formatted with dynamic variables.
    :return: The generated narrative text.
    """
    try:
        response = openai.Completion.create(
            engine="davinci",  # or your preferred engine, e.g., "gpt-3.5-turbo"
            prompt=prompt,
            max_tokens=150,
            temperature=0.8
        )
        narrative_text = response['choices'][0]['text'].strip()
        return narrative_text
    except Exception as error:
        print(f"Error during API call: {error}")
        # If API call fails, return fallback narrative with generic parameters
        return fallback_narrative("unknown", "neutral", "unspecified")

# Define the narrative prompt template
NARRATIVE_TEMPLATE = (
    "Generate a detailed description of a {location_type} environment, "
    "using a {tone} tone. Be sure to include the following elements: {required_elements}."
)

def build_prompt(template, **kwargs):
    """
    Inserts dynamic variables into the provided template.
    
    :param template: A narrative prompt template with placeholders.
    :param kwargs: A dictionary of dynamic values.
    :return: A formatted prompt.
    """
    return template.format(**kwargs)

def validate_narrative(narrative, required_elements):
    """
    Validates the generated narrative text by ensuring it contains all required elements.
    
    :param narrative: The AI-generated narrative text.
    :param required_elements: A comma-separated string of elements that must appear.
    :return: True if all elements are found; otherwise, False.
    """
    required_list = [element.strip().lower() for element in required_elements.split(',')]
    narrative_lower = narrative.lower()
    for element in required_list:
        if element and element not in narrative_lower:
            return False
    return True

def fallback_narrative(location_type, tone, required_elements):
    """
    Provides a fallback narrative snippet when the AI-generated content fails validation
    or the API call encounters an error.
    
    :param location_type: Type of the location.
    :param tone: Desired narrative tone.
    :param required_elements: Key elements that should be included.
    :return: A safe fallback narrative string.
    """
    return (
        f"In this {location_type}, the ambiance is decidedly {tone}. "
        f"While detailed descriptions elude capture, essential elements such as {required_elements} "
        "are subtly suggested by the surroundings."
    )

def generate_dynamic_narrative(location_type, tone, required_elements):
    """
    Combines prompt building, API call, and content validation to generate narrative content dynamically.
    
    :param location_type: The type of location (e.g., 'dungeon', 'forest').
    :param tone: The desired tone (e.g., 'mysterious', 'whimsical').
    :param required_elements: A comma-separated string of key narrative elements.
    :return: AI-generated narrative text that meets validation criteria, or a fallback narrative.
    """
    prompt = build_prompt(
        NARRATIVE_TEMPLATE,
        location_type=location_type,
        tone=tone,
        required_elements=required_elements
    )
    
    narrative = generate_narrative(prompt)
    
    if not validate_narrative(narrative, required_elements):
        narrative = fallback_narrative(location_type, tone, required_elements)
    
    return narrative
```

---

### Implementation Guidance Recap

- **Import OpenAI Library:**  
    Installed using `pip install openai` and imported with `import openai`.
    
- **API Call Function:**  
    `generate_narrative()` builds the API request and handles any exceptions, returning a fallback narrative if needed.
    
- **Dynamic Variables:**  
    `build_prompt()` formats the narrative template with variables like `location_type`, `tone`, and `required_elements`.
    
- **Content Validation:**  
    `validate_narrative()` checks that the generated narrative includes all required elements (using simple case-insensitive substring checks).
    
- **Fallback Handling:**  
    `fallback_narrative()` provides a predefined narrative snippet when the generated content doesn’t pass validation or when an error occurs.
    

This setup keeps your module flexible and robust by integrating dynamic prompt generation, error handling, content validation, and fallback strategies. Let me know if you need anything else, Ian!

---

### 4. Error Handling

- **Try/Except Blocks:**  
    Wrap API calls in try/except blocks to catch exceptions (e.g., network issues, rate limiting, or invalid responses).
    
- **Logging:**  
    Log error messages for troubleshooting.
    
- **Fallback Execution:**  
    Trigger fallback responses if an error occurs.
    


Hey Ian, it's skippy. Below is an updated version of your module that incorporates enhanced error handling using try/except blocks and logging, plus fallback execution. This version logs errors encountered during the API call and triggers fallback responses if needed.

```python
# narrative_engine/ai_generator.py

import os
import redis
import openai
import logging

# Module-level variables to hold configuration settings
OPENAI_API_KEY = None
REDIS_URL = None
redis_client = None

# Set up a logger for this module
logger = logging.getLogger(__name__)

def init_app(app):
    """
    Initialize the AI generator module with settings from a Flask app.
    Expected configuration keys:
      - OPENAI_API_KEY
      - REDIS_URL
    """
    global OPENAI_API_KEY, REDIS_URL, redis_client
    
    OPENAI_API_KEY = app.config.get('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY'))
    REDIS_URL = app.config.get('REDIS_URL', os.environ.get('REDIS_URL'))
    
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API key is not set. Please define it in your config or set the OPENAI_API_KEY environment variable.")
    if not REDIS_URL:
        raise ValueError("Redis URL is not set. Please define it in your config or set the REDIS_URL environment variable.")
    
    openai.api_key = OPENAI_API_KEY
    redis_client = redis.Redis.from_url(REDIS_URL)
    
    app.logger.info("AI Generator module initialized with OpenAI API and Redis.")

def generate_narrative(prompt):
    """
    Generates narrative content using the OpenAI API based on the provided prompt.

    :param prompt: The string prompt, formatted with dynamic variables.
    :return: The generated narrative text.
    """
    try:
        response = openai.Completion.create(
            engine="davinci",  # or your preferred engine, e.g., "gpt-3.5-turbo"
            prompt=prompt,
            max_tokens=150,
            temperature=0.8
        )
        narrative_text = response['choices'][0]['text'].strip()
        return narrative_text
    except Exception as error:
        # Log the error for troubleshooting
        logger.error("Error during API call: %s", error)
        # Trigger fallback narrative if an error occurs
        return fallback_narrative("unknown", "neutral", "unspecified")

# Define the narrative prompt template
NARRATIVE_TEMPLATE = (
    "Generate a detailed description of a {location_type} environment, "
    "using a {tone} tone. Be sure to include the following elements: {required_elements}."
)

def build_prompt(template, **kwargs):
    """
    Inserts dynamic variables into the provided template.
    
    :param template: A narrative prompt template with placeholders.
    :param kwargs: A dictionary of dynamic values.
    :return: A formatted prompt.
    """
    return template.format(**kwargs)

def validate_narrative(narrative, required_elements):
    """
    Validates the generated narrative text by ensuring it contains all required elements.
    
    :param narrative: The AI-generated narrative text.
    :param required_elements: A comma-separated string of elements that must appear.
    :return: True if all elements are found; otherwise, False.
    """
    required_list = [element.strip().lower() for element in required_elements.split(',')]
    narrative_lower = narrative.lower()
    for element in required_list:
        if element and element not in narrative_lower:
            return False
    return True

def fallback_narrative(location_type, tone, required_elements):
    """
    Provides a fallback narrative snippet when the AI-generated content fails validation
    or the API call encounters an error.
    
    :param location_type: Type of the location.
    :param tone: Desired narrative tone.
    :param required_elements: Key elements that should be included.
    :return: A safe fallback narrative string.
    """
    return (
        f"In this {location_type}, the ambiance is decidedly {tone}. "
        f"While detailed descriptions elude capture, essential elements such as {required_elements} "
        "are subtly suggested by the surroundings."
    )

def generate_dynamic_narrative(location_type, tone, required_elements):
    """
    Combines prompt building, API call, and content validation to generate narrative content dynamically.
    
    :param location_type: The type of location (e.g., 'dungeon', 'forest').
    :param tone: The desired tone (e.g., 'mysterious', 'whimsical').
    :param required_elements: A comma-separated string of key narrative elements.
    :return: AI-generated narrative text that meets validation criteria, or a fallback narrative.
    """
    prompt = build_prompt(
        NARRATIVE_TEMPLATE,
        location_type=location_type,
        tone=tone,
        required_elements=required_elements
    )
    
    narrative = generate_narrative(prompt)
    
    if not validate_narrative(narrative, required_elements):
        logger.warning("Generated narrative failed validation. Using fallback narrative.")
        narrative = fallback_narrative(location_type, tone, required_elements)
    
    return narrative
```

---

### Implementation Guidance Recap

- **Try/Except Blocks:**  
    The `generate_narrative()` function now wraps the API call in a try/except block, logging any errors encountered.
    
- **Logging:**  
    Errors are logged via the `logger.error()` method, and warnings are issued if the narrative fails validation before falling back to a safe snippet.
    
- **Fallback Execution:**  
    If an error occurs during the API call or the generated narrative doesn’t pass validation, `fallback_narrative()` provides a safe narrative output.
    

This setup ensures that your module robustly handles errors during AI integration and provides meaningful fallback content. Let me know if you need any further adjustments, Ian!

---

### 5. Caching with Redis

- **Integrate Redis:**  
    Use the `redis-py` library to:
    
    - Connect to a Redis server.
        
    - Store generated narrative content.
    - Create a configuration based feature flag to enable/disable redis caching 
        
- **Cache Key Strategy:**  
    Develop a system that calculates a unique key for each prompt (perhaps a hash of the prompt template and dynamic values).
    
- **Retrieve and Store:**  
    Before making an API call, check if the response for the prompt is already cached. If not, store the new response in Redis after successfully generating it.
    

Hey Ian, it's skippy. Below is an updated version of your `ai_generator.py` file that integrates Redis caching with a configurable feature flag. The code calculates a unique cache key for each generated prompt (using a SHA-256 hash), checks if the narrative for that prompt is already in Redis, and stores new responses if not. It also keeps your existing error handling, content validation, and fallback logic.

```python
# narrative_engine/ai_generator.py

import os
import redis
import openai
import logging
import hashlib

# Module-level variables to hold configuration settings
OPENAI_API_KEY = None
REDIS_URL = None
redis_client = None
CACHING_ENABLED = True  # Default to enabled; can be configured via app settings

# Set up a logger for this module
logger = logging.getLogger(__name__)

def init_app(app):
    """
    Initialize the AI generator module with settings from a Flask app.
    Expected configuration keys:
      - OPENAI_API_KEY
      - REDIS_URL
      - REDIS_CACHING_ENABLED (optional, defaults to True)
    """
    global OPENAI_API_KEY, REDIS_URL, redis_client, CACHING_ENABLED

    OPENAI_API_KEY = app.config.get('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY'))
    REDIS_URL = app.config.get('REDIS_URL', os.environ.get('REDIS_URL'))
    CACHING_ENABLED = app.config.get('REDIS_CACHING_ENABLED', True)
    
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API key is not set. Please define it in your config or set the OPENAI_API_KEY environment variable.")
    if not REDIS_URL:
        raise ValueError("Redis URL is not set. Please define it in your config or set the REDIS_URL environment variable.")
    
    openai.api_key = OPENAI_API_KEY
    redis_client = redis.Redis.from_url(REDIS_URL)
    
    app.logger.info("AI Generator module initialized with OpenAI API and Redis (Caching Enabled: %s).", CACHING_ENABLED)

def generate_narrative(prompt):
    """
    Generates narrative content using the OpenAI API based on the provided prompt.

    :param prompt: The string prompt, formatted with dynamic variables.
    :return: The generated narrative text.
    """
    try:
        response = openai.Completion.create(
            engine="davinci",  # or your preferred engine, e.g., "gpt-3.5-turbo"
            prompt=prompt,
            max_tokens=150,
            temperature=0.8
        )
        narrative_text = response['choices'][0]['text'].strip()
        return narrative_text
    except Exception as error:
        logger.error("Error during API call: %s", error)
        # Trigger fallback narrative if an error occurs
        return fallback_narrative("unknown", "neutral", "unspecified")

# Define the narrative prompt template
NARRATIVE_TEMPLATE = (
    "Generate a detailed description of a {location_type} environment, "
    "using a {tone} tone. Be sure to include the following elements: {required_elements}."
)

def build_prompt(template, **kwargs):
    """
    Inserts dynamic variables into the provided template.
    
    :param template: A narrative prompt template with placeholders.
    :param kwargs: A dictionary of dynamic values.
    :return: A formatted prompt.
    """
    return template.format(**kwargs)

def validate_narrative(narrative, required_elements):
    """
    Validates the generated narrative text by ensuring it contains all required elements.
    
    :param narrative: The AI-generated narrative text.
    :param required_elements: A comma-separated string of elements that must appear.
    :return: True if all elements are found; otherwise, False.
    """
    required_list = [element.strip().lower() for element in required_elements.split(',')]
    narrative_lower = narrative.lower()
    for element in required_list:
        if element and element not in narrative_lower:
            return False
    return True

def fallback_narrative(location_type, tone, required_elements):
    """
    Provides a fallback narrative snippet when the AI-generated content fails validation
    or the API call encounters an error.
    
    :param location_type: Type of the location.
    :param tone: Desired narrative tone.
    :param required_elements: Key elements that should be included.
    :return: A safe fallback narrative string.
    """
    return (
        f"In this {location_type}, the ambiance is decidedly {tone}. "
        f"While detailed descriptions elude capture, essential elements such as {required_elements} "
        "are subtly suggested by the surroundings."
    )

def generate_dynamic_narrative(location_type, tone, required_elements):
    """
    Combines prompt building, caching, API call, and content validation to generate narrative content dynamically.
    
    :param location_type: The type of location (e.g., 'dungeon', 'forest').
    :param tone: The desired tone (e.g., 'mysterious', 'whimsical').
    :param required_elements: A comma-separated string of key narrative elements.
    :return: AI-generated narrative text that meets validation criteria, or a fallback narrative.
    """
    prompt = build_prompt(
        NARRATIVE_TEMPLATE,
        location_type=location_type,
        tone=tone,
        required_elements=required_elements
    )

    # Create a unique cache key based on the prompt
    cache_key = hashlib.sha256(prompt.encode('utf-8')).hexdigest()

    # Check if caching is enabled and attempt to retrieve cached content
    if CACHING_ENABLED and redis_client:
        cached_narrative = redis_client.get(cache_key)
        if cached_narrative:
            logger.info("Using cached narrative for prompt: %s", prompt)
            return cached_narrative.decode('utf-8')
    
    # Generate narrative content via the OpenAI API
    narrative = generate_narrative(prompt)
    
    # Validate the generated narrative; if it fails, use the fallback
    if not validate_narrative(narrative, required_elements):
        logger.warning("Generated narrative failed validation. Using fallback narrative.")
        narrative = fallback_narrative(location_type, tone, required_elements)
    
    # Store the generated narrative in Redis if caching is enabled
    if CACHING_ENABLED and redis_client:
        try:
            redis_client.set(cache_key, narrative)
        except Exception as cache_error:
            logger.error("Error storing narrative in Redis: %s", cache_error)
    
    return narrative
```

---

### Guidance Recap

1. **Integrate Redis with a Feature Flag:**
    
    - The module now reads a configuration flag (`REDIS_CACHING_ENABLED`) from your Flask app. This flag determines if caching is enabled.
        
    - In `init_app`, the Redis client is initialized using the configured Redis URL.
        
2. **Cache Key Strategy:**
    
    - A unique key for each prompt is generated using SHA-256 of the prompt string. This key is used to check for and store responses in Redis.
        
3. **Retrieve and Store Mechanism:**
    
    - Before making an API call, the `generate_dynamic_narrative` function checks the Redis cache for a stored response.
        
    - If found, it returns the cached narrative. Otherwise, it generates the narrative, validates it, and then stores the result in Redis.
        

Let me know if you need more tweaks or additional guidance, Ian!

---

### 6. Narrative Memory and Coherence

- **Memory Log:**  
    Optionally, maintain a narrative memory log that keeps track of previous significant narrative events. This can:
    
    - Help in generating context-aware narrative.
        
    - Serve as a consistency check for long sessions.
    - This can be created in a new class in a new file
    - ensure it works with `def generate_dynamic_narrative` in `ai_generator.py`
        
- **Integration:**  
    Ensure your content generation function can access and update this memory log as needed.
    

Hey Ian, it's skippy. Below you'll find guidance and the updated code that adds a Narrative Memory system to help maintain context and coherence during long sessions. We'll create a new file for the memory log and update the dynamic narrative generator to interact with it.

---

## 1. Create a New File for Narrative Memory

Create a file called `narrative_memory.py` inside your `narrative_engine` directory. This file defines the `NarrativeMemory` class, which logs narrative events. For example:

```python
# narrative_engine/narrative_memory.py

class NarrativeMemory:
    def __init__(self):
        self.events = []

    def add_event(self, event):
        """
        Add a narrative event to the memory log.
        
        :param event: A narrative event as a string.
        """
        self.events.append(event)

    def get_log(self):
        """
        Return the entire narrative memory log as a single string.
        The log is prefixed with a header to indicate context.
        
        :return: A string combining all previous narrative events.
        """
        if self.events:
            return "Previous events:\n" + "\n".join(self.events) + "\n"
        return ""
    
    def clear(self):
        """
        Clear the narrative memory log.
        """
        self.events = []
```

This class helps track previous narrative events. You can expand it later—for example, adding timestamps or filtering for significant events.

---

## 2. Update the AI Generator Module to Integrate Narrative Memory

Next, update your existing `ai_generator.py` file to accept an optional memory log. We'll modify the narrative template and the `generate_dynamic_narrative` function as follows:

- **Narrative Template:**  
    Update the template to optionally include a memory log.
    
- **Function Parameter:**  
    Add an optional `memory` parameter. When provided, the generator will prepend the memory log to the prompt and update it with the new narrative.
    

Below is the updated `ai_generator.py` with Redis caching, error handling, content validation, fallback handling, and narrative memory integration:

```python
# narrative_engine/ai_generator.py

import os
import redis
import openai
import logging
import hashlib
from .narrative_memory import NarrativeMemory  # Import the memory module

# Module-level variables to hold configuration settings
OPENAI_API_KEY = None
REDIS_URL = None
redis_client = None
CACHING_ENABLED = True  # Default to enabled; can be configured via app settings

# Set up a logger for this module
logger = logging.getLogger(__name__)

def init_app(app):
    """
    Initialize the AI generator module with settings from a Flask app.
    Expected configuration keys:
      - OPENAI_API_KEY
      - REDIS_URL
      - REDIS_CACHING_ENABLED (optional, defaults to True)
    """
    global OPENAI_API_KEY, REDIS_URL, redis_client, CACHING_ENABLED

    OPENAI_API_KEY = app.config.get('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY'))
    REDIS_URL = app.config.get('REDIS_URL', os.environ.get('REDIS_URL'))
    CACHING_ENABLED = app.config.get('REDIS_CACHING_ENABLED', True)
    
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API key is not set. Please define it in your config or set the OPENAI_API_KEY environment variable.")
    if not REDIS_URL:
        raise ValueError("Redis URL is not set. Please define it in your config or set the REDIS_URL environment variable.")
    
    openai.api_key = OPENAI_API_KEY
    redis_client = redis.Redis.from_url(REDIS_URL)
    
    app.logger.info("AI Generator module initialized with OpenAI API and Redis (Caching Enabled: %s).", CACHING_ENABLED)

def generate_narrative(prompt):
    """
    Generates narrative content using the OpenAI API based on the provided prompt.

    :param prompt: The string prompt, formatted with dynamic variables.
    :return: The generated narrative text.
    """
    try:
        response = openai.Completion.create(
            engine="davinci",  # or your preferred engine, e.g., "gpt-3.5-turbo"
            prompt=prompt,
            max_tokens=150,
            temperature=0.8
        )
        narrative_text = response['choices'][0]['text'].strip()
        return narrative_text
    except Exception as error:
        logger.error("Error during API call: %s", error)
        # Trigger fallback narrative if an error occurs
        return fallback_narrative("unknown", "neutral", "unspecified")

# Update the narrative prompt template to include a memory log segment.
NARRATIVE_TEMPLATE = (
    "{memory_log}"
    "Generate a detailed description of a {location_type} environment, "
    "using a {tone} tone. Be sure to include the following elements: {required_elements}."
)

def build_prompt(template, **kwargs):
    """
    Inserts dynamic variables into the provided template.
    
    :param template: A narrative prompt template with placeholders.
    :param kwargs: A dictionary of dynamic values.
    :return: A formatted prompt.
    """
    return template.format(**kwargs)

def validate_narrative(narrative, required_elements):
    """
    Validates the generated narrative text by ensuring it contains all required elements.
    
    :param narrative: The AI-generated narrative text.
    :param required_elements: A comma-separated string of elements that must appear.
    :return: True if all elements are found; otherwise, False.
    """
    required_list = [element.strip().lower() for element in required_elements.split(',')]
    narrative_lower = narrative.lower()
    for element in required_list:
        if element and element not in narrative_lower:
            return False
    return True

def fallback_narrative(location_type, tone, required_elements):
    """
    Provides a fallback narrative snippet when the AI-generated content fails validation
    or the API call encounters an error.
    
    :param location_type: Type of the location.
    :param tone: Desired narrative tone.
    :param required_elements: Key elements that should be included.
    :return: A safe fallback narrative string.
    """
    return (
        f"In this {location_type}, the ambiance is decidedly {tone}. "
        f"While detailed descriptions elude capture, essential elements such as {required_elements} "
        "are subtly suggested by the surroundings."
    )

def generate_dynamic_narrative(location_type, tone, required_elements, memory: NarrativeMemory = None):
    """
    Combines prompt building, caching, API call, content validation, and narrative memory to generate narrative content dynamically.
    
    :param location_type: The type of location (e.g., 'dungeon', 'forest').
    :param tone: The desired tone (e.g., 'mysterious', 'whimsical').
    :param required_elements: A comma-separated string of key narrative elements.
    :param memory: (Optional) An instance of NarrativeMemory to incorporate previous narrative events.
    :return: AI-generated narrative text that meets validation criteria, or a fallback narrative.
    """
    # Retrieve memory log if a memory instance is provided
    memory_log = memory.get_log() if memory else ""
    
    # Build the prompt with dynamic variables and the current memory log
    prompt = build_prompt(
        NARRATIVE_TEMPLATE,
        memory_log=memory_log,
        location_type=location_type,
        tone=tone,
        required_elements=required_elements
    )

    # Create a unique cache key based on the prompt
    cache_key = hashlib.sha256(prompt.encode('utf-8')).hexdigest()

    # Check if caching is enabled and try to retrieve cached content
    if CACHING_ENABLED and redis_client:
        cached_narrative = redis_client.get(cache_key)
        if cached_narrative:
            logger.info("Using cached narrative for prompt: %s", prompt)
            narrative = cached_narrative.decode('utf-8')
        else:
            narrative = generate_narrative(prompt)
    else:
        narrative = generate_narrative(prompt)
    
    # Validate the generated narrative; if it fails, use the fallback
    if not validate_narrative(narrative, required_elements):
        logger.warning("Generated narrative failed validation. Using fallback narrative.")
        narrative = fallback_narrative(location_type, tone, required_elements)
    
    # Store the generated narrative in Redis if caching is enabled
    if CACHING_ENABLED and redis_client:
        try:
            redis_client.set(cache_key, narrative)
        except Exception as cache_error:
            logger.error("Error storing narrative in Redis: %s", cache_error)
    
    # Update narrative memory if provided
    if memory:
        memory.add_event(narrative)
    
    return narrative
```

---

## How It Works

1. **Narrative Memory Class:**
    
    - The `NarrativeMemory` class (in `narrative_memory.py`) keeps a list of narrative events.
        
    - The `get_log()` method returns a concatenated string of previous events, which is prepended to the prompt for context.
        
    - The `add_event()` method logs each newly generated narrative.
        
2. **Integration in `generate_dynamic_narrative`:**
    
    - An optional `memory` parameter is added.
        
    - If provided, the function retrieves the memory log and passes it into the prompt (`{memory_log}` placeholder).
        
    - After generating the narrative, it logs the event to the memory.
        
3. **Cache & Fallback:**
    
    - The function calculates a unique cache key (using a SHA-256 hash of the prompt) and checks Redis before making an API call.
        
    - If validation fails or an error occurs, fallback narrative text is used.
        

This design ensures your content generation is context-aware and maintains a memory log for better narrative coherence over long sessions. Let me know if you need further tweaks or additional guidance, Ian!

---

### 7. Testing and Documentation

- **Unit Testing:**  
    Write tests to simulate different dynamic variable inputs and ensure your module:
    
    - Correctly formats prompts.
        
    - Handles API responses (successful and error cases).
        
    - Properly caches responses.
        
- **Documentation:**  
    Provide clear instructions and examples in the module’s docstrings on:
    
    - How to initialize and use the module.
        
    - Configuration of API keys, Redis connections, and dynamic prompt substitution.
        

---

### Recap

To sum it up, here are the main things you need to do:

- **Module Setup:** Create a new module file and set up configuration handling.
    
- **API Integration:** Write functions to call the OpenAI API, inserting dynamic variables into your narrative prompt templates.
    
- **Prompt Management & Validation:** Develop prompt templating and validation logic, including fallbacks for unsatisfactory output.
    
- **Error Handling:** Implement robust error catching and logging for API calls.
    
- **Redis Caching:** Integrate Redis caching to store and retrieve AI-generated content efficiently.
    
- **Narrative Memory:** (Optional) Maintain a memory log for narrative coherence.
    
- **Testing and Documentation:** Ensure the module is well-tested and clearly documented for integration in your broader game engine.
    

Following these steps will help you build a flexible, robust module that leverages AI for dynamic narrative generation while ensuring performance and reliability. Let me know if you need further details on any part of this, Ian!